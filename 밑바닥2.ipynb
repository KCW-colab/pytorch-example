{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "밑바닥2",
      "provenance": [],
      "collapsed_sections": [
        "Gq0ZAt6v5HXp",
        "goYE__qvQVft"
      ],
      "toc_visible": true,
      "mount_file_id": "1qmvcbV1IW_HI8b4PePRIxhS6Fgq5kf0L",
      "authorship_tag": "ABX9TyNHhu2b3md3blDQoAw9S3DL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KCW-colab/pytorch-example/blob/master/%EB%B0%91%EB%B0%94%EB%8B%A52.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbGxUNFXuVQj",
        "colab_type": "text"
      },
      "source": [
        "행아웃 https://hangouts.google.com/call/H1BT80UlutUsEG3guXgpACEM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq0ZAt6v5HXp",
        "colab_type": "text"
      },
      "source": [
        "### 1장 - 신경망 복습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_iXpOH0tCEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a57c7be9-228d-416d-ce40-d029f5bd10c7"
      },
      "source": [
        "import numpy as np\n",
        "x = np.array([1, 2, 3])\n",
        "x.__class__ # 클래스 이름 표시\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNHAo01L0MKr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d00e473a-296b-4471-8ade-7302e9267237"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POHa_JbT0j-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25c5258a-1b60-43f7-837a-6e9a67c46215"
      },
      "source": [
        "x.ndim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgp5ohkX0kvH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ce62fb4-c70e-4e57-eff5-d0f2ec2eedac"
      },
      "source": [
        "W = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "W.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzvw5n7Z0orA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ee1c30d-2f15-495d-e589-281689ba747d"
      },
      "source": [
        "W.ndim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JlvLlwS0qD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "5ade66f2-deef-44dd-bb16-a8bdd0149a6c"
      },
      "source": [
        "W = np.array([[1, 2, 3,], [4, 5, 6]])\n",
        "X = np.array([[0, 1, 2], [3, 4, 5]])\n",
        "print(W + X)\n",
        "print(W*X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  3  5]\n",
            " [ 7  9 11]]\n",
            "[[ 0  2  6]\n",
            " [12 20 30]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c1VeHdD1rKQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ba19e7c2-4b54-4334-9bf5-316bc9b9a3f6"
      },
      "source": [
        "A = np.array([[1, 2], [3, 4]])\n",
        "A * 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10, 20],\n",
              "       [30, 40]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnAmMdyf1vS4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d68260c5-5f37-4722-dff2-8a546e6ebc21"
      },
      "source": [
        "b = np.array([10, 20])\n",
        "A * b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10, 40],\n",
              "       [30, 80]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bch28YLU2CMO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e2024d84-c187-4d32-c7cd-390a7ed2e882"
      },
      "source": [
        "# 벡터의 내적\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([4, 5, 6])\n",
        "print(np.dot(a,b))\n",
        "\n",
        " # 행렬의 곱\n",
        "A = np.array([[1, 2], [3, 4]])\n",
        "B = np.array([[5, 6], [7, 8]])\n",
        "np.matmul(A, B)\n",
        "\n",
        "# 2차원 까지는 np.dot이나 matmul의 역할이 같음."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19, 22],\n",
              "       [43, 50]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yKqW4Zm28cu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "674359d2-59e6-4576-d7a0-84cd960404ae"
      },
      "source": [
        "import numpy as np\n",
        "W1 = np.random.randn(2, 4) # 가중치\n",
        "b1 = np.random.randn(4) # 편향\n",
        "x = np.random.randn(10, 2) # 입력\n",
        "h = np.matmul(x, W1) + b1\n",
        "print(h.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDCirWiZ4Izj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / ( 1+ np.exp(-x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBreFgt94563",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = sigmoid(h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NCwSWkl49QX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac219536-dd87-43d5-f1f2-1c033686396f"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "x = np.random.randn(10, 2) \n",
        "W1 = np.random.randn(2, 4) \n",
        "b1 = np.random.randn(4)\n",
        "W2 = np.random.randn(4, 3) \n",
        "b2 = np.random.randn(3)\n",
        "\n",
        "h = np.matmul(x, W1) + b1\n",
        "a = sigmoid(h)\n",
        "s = np.matmul(a, W2) + b2\n",
        "print(s.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ls93tO35Z_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "class Sigmoid:\n",
        "  def __init__(self):\n",
        "    self.params=[]\n",
        "\n",
        "  def forward(self, x):\n",
        "    return 1 / ( 1+ np.exp(-x))\n",
        "\n",
        "class Affine:\n",
        "  def __init__(self, W, b):\n",
        "    self.params = [W, b]\n",
        "\n",
        "  def forward(self, x):\n",
        "    W, b = self.params\n",
        "    out = np.matmul(x, W) + b\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnuivKye6u3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TwoLayerNet:\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    I, H, O = input_size, hidden_size, output_size\n",
        "\n",
        "    # 가중치와 편향 초기화\n",
        "    W1 = np.random.randn(I, H)\n",
        "    b1 = np.random.randn(H)\n",
        "    W2 = np.random.randn(H, O)\n",
        "    b2 = np.random.randn(O)\n",
        "\n",
        "    # 게층 생성\n",
        "    self.layers = [Affine(W1, b1), Sigmoid(), Affine(W2, b2)]\n",
        "\n",
        "    # 모든 가중치를 리스트에 모은다.\n",
        "    self.params=[]\n",
        "    for layer in self.layers:\n",
        "      self.params += layer.params\n",
        "\n",
        "  def predict(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer.forward(x)\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vkg405qs8CCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6f14f00-2964-451f-fb46-3a098ade4f13"
      },
      "source": [
        "x = np.random.randn(10, 2)\n",
        "model = TwoLayerNet(2, 4, 3)\n",
        "s = model.predict(x)\n",
        "print(s.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9PoK-sN9KZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "D, N  = 8 , 7\n",
        "x = np.random.randn(1, D) # 입력\n",
        "y = np.repeat(x, N, axis = 0) # 순전파  # 원소 복제를 시행하는 numpy의 함수 (x 를 N번 복제하는데 세로방향으로 복제함.)\n",
        "# y.shape = (7,8)\n",
        "dy = np.random.randn(N, D) # 무작위 기울기\n",
        "dx = np.sum(dy, axis = 0, keepdims=True) # 역전파 # 2차원 유지를 위해 keepdims = True로 둠."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-si--2GXE6vk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "D, N = 8, 7\n",
        "x = np.random.randn(N, D) # 입력\n",
        "y = np.sum(x, axis = 0, keepdims = True) # 순전파\n",
        "dy = np.random.randn(1, D) # 무작위 기울기\n",
        "dx = np.repeat(dy, N, axis=0) # 역전파\n",
        "# Sum 노드와 repeat 노드는 반대관계임.\n",
        "# ex) Sum 노드의 순전파 => repeat 노드의 역전파"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rptCDofyFmI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MatMul:\n",
        "  def __init__(self, W):\n",
        "    self.params = [W]\n",
        "    self.grads = [np.zeros_like(W)]\n",
        "    self.x = None\n",
        "  \n",
        "  def forward(self, x):\n",
        "    W, = self.params\n",
        "    out = np.matmul(x, W)\n",
        "    self.x = x\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    W, = self.params\n",
        "    dx = np.matmul(dout, W.T)\n",
        "    dW = np.matmul(self.x.T, dout)\n",
        "    self.grads[0][...] = dW\n",
        "    return dx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrtq_N8dGt2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6ef3f528-91a9-4cc3-bd02-1fb7a959907a"
      },
      "source": [
        "'''\n",
        "얕은 복사는 본품의 메모리값을 복사하는 것임.\n",
        "깊은 복사는 본품의 숫자 자체를 복사해오는 것\n",
        "\n",
        "얕은 복사 종류\n",
        "list1 = [1, 2, 3]\n",
        "list2 = list1\n",
        "\n",
        "깊은 복사 종류\n",
        "list2 = list1[:]\n",
        "list2 = list1.copy\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n얕은 복사는 본품의 메모리값을 복사하는 것임.\\n깊은 복사는 본품의 숫자 자체를 복사해오는 것\\n\\n얕은 복사 종류\\nlist1 = [1, 2, 3]\\nlist2 = list1\\n\\n깊은 복사 종류\\nlist2 = list1[:]\\nlist2 = list1.copy\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1eU4nilIJ3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sigmoid:\n",
        "  def __init__(self):\n",
        "    self.params, self.grads = [], []\n",
        "    self.out = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = 1 / (1 + np.exp(-x))\n",
        "    self.out = out\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dx = dout * (1.0 - self.out) * self.out\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnhI1irdIqnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Affine:\n",
        "  def __init__(self, W, b):\n",
        "    self.params = [W, b]\n",
        "    self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
        "    self.x = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    W, b = self.params\n",
        "    out = np.matmul(x, W) + b\n",
        "    self.x = x\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    W, b = self.params\n",
        "    dx = np.matmul(dout, W.T)\n",
        "    dW = np.matmul(self.x.T, dout)\n",
        "    db = np.sum(dout, axis = 0)\n",
        "\n",
        "    self.grads[0][...] = dW\n",
        "    self.grads[1][...] = db\n",
        "    return dx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82M6OnzHKGSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SGD:\n",
        "  def __init__(self, lr=0.01):\n",
        "    self.lr = lr\n",
        "\n",
        "  def update(self, params, grads):\n",
        "    for i in range(len(params)):\n",
        "      params[i] -= self.lr * grads[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjQDfoLDK2fE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "0204c60c-8a9b-4650-98db-4ecacc7e0ffa"
      },
      "source": [
        "import sys, os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append(os.pardir)\n",
        "\n",
        "\n",
        "from dataset import spiral\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x,t = spiral.load_data()\n",
        "print('x', x.shape) # (300, 2)\n",
        "print('t', t.shape) # (300, 3)\n",
        "\n",
        "'''\n",
        "# 데이터점 플롯\n",
        "N = 100\n",
        "CLS_NUM = 3\n",
        "markers = ['o', 'x', '^']\n",
        "for i in range(CLS_NUM):\n",
        "    plt.scatter(x[i*N:(i+1)*N, 0], x[i*N:(i+1)*N, 1], s=40, marker=markers[i])\n",
        "plt.show()\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x (300, 2)\n",
            "t (300, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# 데이터점 플롯\\nN = 100\\nCLS_NUM = 3\\nmarkers = ['o', 'x', '^']\\nfor i in range(CLS_NUM):\\n    plt.scatter(x[i*N:(i+1)*N, 0], x[i*N:(i+1)*N, 1], s=40, marker=markers[i])\\nplt.show()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga7r1t2C5PT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys, os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append(os.pardir)\n",
        "import numpy as np\n",
        "from common.layers import Affine, Sigmoid, SoftmaxWithLoss\n",
        "\n",
        "class TwoLayerNet:\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    I, H, O = input_size, hidden_size, output_size\n",
        "\n",
        "    # 가중치와 편향 초기화\n",
        "    W1 = 0.01 * np.random.randn(I, H)\n",
        "    b1 = np.zeros(H)\n",
        "    W2 = 0.01 * np.random.randn(H, O)\n",
        "    b2 = np.zeros(0)\n",
        "\n",
        "    # 계층 생성\n",
        "    self.layers = [Affine(W1, b1), Sigmoid(), Affine(W2, b2)]\n",
        "    self.loss_layer = SoftmaxWithLoss()\n",
        "\n",
        "    # 모든 가중치와 기울기를 리스트에 모은다.\n",
        "    self.params, self.grads = [], []\n",
        "    for layer in self.layers:\n",
        "      self.params += layer.params\n",
        "      self.grads += layer.grads\n",
        "\n",
        "  def predict(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer.forward(x)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x, t):\n",
        "    score = self.predict(x)\n",
        "    loss = self.loss_layer.forward(score, t)\n",
        "    return loss\n",
        "\n",
        "\n",
        "  def backward(self, dout = 1):\n",
        "    dout = self.loss_layer.backward(dout)\n",
        "    for layer in reversed(self.layers):\n",
        "      dout = layer.backward(dout)\n",
        "    return dout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePuS_Ue19iil",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8591f2a-1f85-4c13-f639-56c4b89b341c"
      },
      "source": [
        "import sys, os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/deep-learning-from-scratch-2-master\")\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/deep-learning-from-scratch-2-master/ch01\")\n",
        "sys.path.append(os.pardir)\n",
        "import numpy as np\n",
        "from common.optimizer import SGD\n",
        "from dataset import spiral\n",
        "import matplotlib.pyplot as plt\n",
        "from two_layer_net import TwoLayerNet\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "max_epoch = 300 # 학습하는 에폭 수\n",
        "batch_size = 30 # 미니배치 크기\n",
        "hidden_size = 10 # 은닉층의 뉴런 수\n",
        "learning_rate = 1.0 # 학습률\n",
        "\n",
        "\n",
        "x, t = spiral.load_data()\n",
        "# 데이터 읽기\n",
        "model = TwoLayerNet(input_size = 2, hidden_size = hidden_size, output_size = 3)\n",
        "# 신경망 모델 생성\n",
        "optimizer = SGD(lr = learning_rate)\n",
        "# SGD 모델 생성\n",
        "# 에폭은 학습 단위로서, 1에폭은 학습 데이터를 모두 '살펴본' 시점.\n",
        "\n",
        "# 학습에 사용하는 변수\n",
        "data_size = len(x)\n",
        "max_iters = data_size // batch_size  # // 연산자는 나눗셈 후 소숫점을 버리는 연산자.\n",
        "total_loss = 0\n",
        "loss_count = 0\n",
        "loss_list = []\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "  # 데이터 뒤섞기\n",
        "  idx = np.random.permutation(data_size)\n",
        "  x = x[idx]\n",
        "  t = t[idx]\n",
        "\n",
        "  for iters in range(max_iters):\n",
        "    batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
        "    batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
        "\n",
        "  # 기울기를 구해 매개변수 갱신\n",
        "    loss = model.forward(batch_x, batch_t)\n",
        "    model.backward()\n",
        "    optimizer.update(model.params, model.grads)\n",
        "\n",
        "  # 역전파 순전파를 이용해서 기울기들을 모두저장\n",
        "\n",
        "    total_loss += loss\n",
        "    loss_count += 1\n",
        "\n",
        "  \n",
        "\n",
        "  # 정기적으로 학습 경과 출력\n",
        "    if (iters+1) % 10 == 0:\n",
        "      avg_loss = total_loss / loss_count\n",
        "      print('|에폭 %d| 반복 %d / %d | 손실 %.2f' %(epoch+1, iters+1, max_iters, avg_loss))\n",
        "      loss_list.append(avg_loss)\n",
        "      total_loss, loss_count = 0, 0\n",
        "\n",
        "# 학습 결과 플롯\n",
        "plt.plot(np.arange(len(loss_list)), loss_list, label='train')\n",
        "plt.xlabel('반복 (x10)')\n",
        "plt.ylabel('손실')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|에폭 1| 반복 10 / 10 | 손실 1.13\n",
            "|에폭 2| 반복 10 / 10 | 손실 1.13\n",
            "|에폭 3| 반복 10 / 10 | 손실 1.12\n",
            "|에폭 4| 반복 10 / 10 | 손실 1.12\n",
            "|에폭 5| 반복 10 / 10 | 손실 1.11\n",
            "|에폭 6| 반복 10 / 10 | 손실 1.14\n",
            "|에폭 7| 반복 10 / 10 | 손실 1.16\n",
            "|에폭 8| 반복 10 / 10 | 손실 1.11\n",
            "|에폭 9| 반복 10 / 10 | 손실 1.12\n",
            "|에폭 10| 반복 10 / 10 | 손실 1.13\n",
            "|에폭 11| 반복 10 / 10 | 손실 1.12\n",
            "|에폭 12| 반복 10 / 10 | 손실 1.11\n",
            "|에폭 13| 반복 10 / 10 | 손실 1.09\n",
            "|에폭 14| 반복 10 / 10 | 손실 1.08\n",
            "|에폭 15| 반복 10 / 10 | 손실 1.04\n",
            "|에폭 16| 반복 10 / 10 | 손실 1.03\n",
            "|에폭 17| 반복 10 / 10 | 손실 0.96\n",
            "|에폭 18| 반복 10 / 10 | 손실 0.92\n",
            "|에폭 19| 반복 10 / 10 | 손실 0.92\n",
            "|에폭 20| 반복 10 / 10 | 손실 0.87\n",
            "|에폭 21| 반복 10 / 10 | 손실 0.85\n",
            "|에폭 22| 반복 10 / 10 | 손실 0.82\n",
            "|에폭 23| 반복 10 / 10 | 손실 0.79\n",
            "|에폭 24| 반복 10 / 10 | 손실 0.78\n",
            "|에폭 25| 반복 10 / 10 | 손실 0.82\n",
            "|에폭 26| 반복 10 / 10 | 손실 0.78\n",
            "|에폭 27| 반복 10 / 10 | 손실 0.76\n",
            "|에폭 28| 반복 10 / 10 | 손실 0.76\n",
            "|에폭 29| 반복 10 / 10 | 손실 0.78\n",
            "|에폭 30| 반복 10 / 10 | 손실 0.75\n",
            "|에폭 31| 반복 10 / 10 | 손실 0.78\n",
            "|에폭 32| 반복 10 / 10 | 손실 0.77\n",
            "|에폭 33| 반복 10 / 10 | 손실 0.77\n",
            "|에폭 34| 반복 10 / 10 | 손실 0.78\n",
            "|에폭 35| 반복 10 / 10 | 손실 0.75\n",
            "|에폭 36| 반복 10 / 10 | 손실 0.74\n",
            "|에폭 37| 반복 10 / 10 | 손실 0.76\n",
            "|에폭 38| 반복 10 / 10 | 손실 0.76\n",
            "|에폭 39| 반복 10 / 10 | 손실 0.73\n",
            "|에폭 40| 반복 10 / 10 | 손실 0.75\n",
            "|에폭 41| 반복 10 / 10 | 손실 0.76\n",
            "|에폭 42| 반복 10 / 10 | 손실 0.76\n",
            "|에폭 43| 반복 10 / 10 | 손실 0.76\n",
            "|에폭 44| 반복 10 / 10 | 손실 0.74\n",
            "|에폭 45| 반복 10 / 10 | 손실 0.75\n",
            "|에폭 46| 반복 10 / 10 | 손실 0.73\n",
            "|에폭 47| 반복 10 / 10 | 손실 0.72\n",
            "|에폭 48| 반복 10 / 10 | 손실 0.73\n",
            "|에폭 49| 반복 10 / 10 | 손실 0.72\n",
            "|에폭 50| 반복 10 / 10 | 손실 0.72\n",
            "|에폭 51| 반복 10 / 10 | 손실 0.72\n",
            "|에폭 52| 반복 10 / 10 | 손실 0.72\n",
            "|에폭 53| 반복 10 / 10 | 손실 0.74\n",
            "|에폭 54| 반복 10 / 10 | 손실 0.74\n",
            "|에폭 55| 반복 10 / 10 | 손실 0.72\n",
            "|에폭 56| 반복 10 / 10 | 손실 0.72\n",
            "|에폭 57| 반복 10 / 10 | 손실 0.71\n",
            "|에폭 58| 반복 10 / 10 | 손실 0.70\n",
            "|에폭 59| 반복 10 / 10 | 손실 0.72\n",
            "|에폭 60| 반복 10 / 10 | 손실 0.70\n",
            "|에폭 61| 반복 10 / 10 | 손실 0.71\n",
            "|에폭 62| 반복 10 / 10 | 손실 0.72\n",
            "|에폭 63| 반복 10 / 10 | 손실 0.70\n",
            "|에폭 64| 반복 10 / 10 | 손실 0.71\n",
            "|에폭 65| 반복 10 / 10 | 손실 0.73\n",
            "|에폭 66| 반복 10 / 10 | 손실 0.70\n",
            "|에폭 67| 반복 10 / 10 | 손실 0.71\n",
            "|에폭 68| 반복 10 / 10 | 손실 0.69\n",
            "|에폭 69| 반복 10 / 10 | 손실 0.70\n",
            "|에폭 70| 반복 10 / 10 | 손실 0.71\n",
            "|에폭 71| 반복 10 / 10 | 손실 0.68\n",
            "|에폭 72| 반복 10 / 10 | 손실 0.69\n",
            "|에폭 73| 반복 10 / 10 | 손실 0.67\n",
            "|에폭 74| 반복 10 / 10 | 손실 0.68\n",
            "|에폭 75| 반복 10 / 10 | 손실 0.67\n",
            "|에폭 76| 반복 10 / 10 | 손실 0.66\n",
            "|에폭 77| 반복 10 / 10 | 손실 0.69\n",
            "|에폭 78| 반복 10 / 10 | 손실 0.64\n",
            "|에폭 79| 반복 10 / 10 | 손실 0.68\n",
            "|에폭 80| 반복 10 / 10 | 손실 0.64\n",
            "|에폭 81| 반복 10 / 10 | 손실 0.64\n",
            "|에폭 82| 반복 10 / 10 | 손실 0.66\n",
            "|에폭 83| 반복 10 / 10 | 손실 0.62\n",
            "|에폭 84| 반복 10 / 10 | 손실 0.62\n",
            "|에폭 85| 반복 10 / 10 | 손실 0.61\n",
            "|에폭 86| 반복 10 / 10 | 손실 0.60\n",
            "|에폭 87| 반복 10 / 10 | 손실 0.60\n",
            "|에폭 88| 반복 10 / 10 | 손실 0.61\n",
            "|에폭 89| 반복 10 / 10 | 손실 0.59\n",
            "|에폭 90| 반복 10 / 10 | 손실 0.58\n",
            "|에폭 91| 반복 10 / 10 | 손실 0.56\n",
            "|에폭 92| 반복 10 / 10 | 손실 0.56\n",
            "|에폭 93| 반복 10 / 10 | 손실 0.54\n",
            "|에폭 94| 반복 10 / 10 | 손실 0.53\n",
            "|에폭 95| 반복 10 / 10 | 손실 0.53\n",
            "|에폭 96| 반복 10 / 10 | 손실 0.52\n",
            "|에폭 97| 반복 10 / 10 | 손실 0.51\n",
            "|에폭 98| 반복 10 / 10 | 손실 0.50\n",
            "|에폭 99| 반복 10 / 10 | 손실 0.48\n",
            "|에폭 100| 반복 10 / 10 | 손실 0.48\n",
            "|에폭 101| 반복 10 / 10 | 손실 0.46\n",
            "|에폭 102| 반복 10 / 10 | 손실 0.45\n",
            "|에폭 103| 반복 10 / 10 | 손실 0.45\n",
            "|에폭 104| 반복 10 / 10 | 손실 0.44\n",
            "|에폭 105| 반복 10 / 10 | 손실 0.44\n",
            "|에폭 106| 반복 10 / 10 | 손실 0.41\n",
            "|에폭 107| 반복 10 / 10 | 손실 0.40\n",
            "|에폭 108| 반복 10 / 10 | 손실 0.41\n",
            "|에폭 109| 반복 10 / 10 | 손실 0.40\n",
            "|에폭 110| 반복 10 / 10 | 손실 0.40\n",
            "|에폭 111| 반복 10 / 10 | 손실 0.38\n",
            "|에폭 112| 반복 10 / 10 | 손실 0.38\n",
            "|에폭 113| 반복 10 / 10 | 손실 0.36\n",
            "|에폭 114| 반복 10 / 10 | 손실 0.37\n",
            "|에폭 115| 반복 10 / 10 | 손실 0.35\n",
            "|에폭 116| 반복 10 / 10 | 손실 0.34\n",
            "|에폭 117| 반복 10 / 10 | 손실 0.34\n",
            "|에폭 118| 반복 10 / 10 | 손실 0.34\n",
            "|에폭 119| 반복 10 / 10 | 손실 0.33\n",
            "|에폭 120| 반복 10 / 10 | 손실 0.34\n",
            "|에폭 121| 반복 10 / 10 | 손실 0.32\n",
            "|에폭 122| 반복 10 / 10 | 손실 0.32\n",
            "|에폭 123| 반복 10 / 10 | 손실 0.31\n",
            "|에폭 124| 반복 10 / 10 | 손실 0.31\n",
            "|에폭 125| 반복 10 / 10 | 손실 0.30\n",
            "|에폭 126| 반복 10 / 10 | 손실 0.30\n",
            "|에폭 127| 반복 10 / 10 | 손실 0.28\n",
            "|에폭 128| 반복 10 / 10 | 손실 0.28\n",
            "|에폭 129| 반복 10 / 10 | 손실 0.28\n",
            "|에폭 130| 반복 10 / 10 | 손실 0.28\n",
            "|에폭 131| 반복 10 / 10 | 손실 0.27\n",
            "|에폭 132| 반복 10 / 10 | 손실 0.27\n",
            "|에폭 133| 반복 10 / 10 | 손실 0.27\n",
            "|에폭 134| 반복 10 / 10 | 손실 0.27\n",
            "|에폭 135| 반복 10 / 10 | 손실 0.27\n",
            "|에폭 136| 반복 10 / 10 | 손실 0.26\n",
            "|에폭 137| 반복 10 / 10 | 손실 0.26\n",
            "|에폭 138| 반복 10 / 10 | 손실 0.26\n",
            "|에폭 139| 반복 10 / 10 | 손실 0.25\n",
            "|에폭 140| 반복 10 / 10 | 손실 0.24\n",
            "|에폭 141| 반복 10 / 10 | 손실 0.24\n",
            "|에폭 142| 반복 10 / 10 | 손실 0.25\n",
            "|에폭 143| 반복 10 / 10 | 손실 0.24\n",
            "|에폭 144| 반복 10 / 10 | 손실 0.24\n",
            "|에폭 145| 반복 10 / 10 | 손실 0.23\n",
            "|에폭 146| 반복 10 / 10 | 손실 0.24\n",
            "|에폭 147| 반복 10 / 10 | 손실 0.23\n",
            "|에폭 148| 반복 10 / 10 | 손실 0.23\n",
            "|에폭 149| 반복 10 / 10 | 손실 0.22\n",
            "|에폭 150| 반복 10 / 10 | 손실 0.22\n",
            "|에폭 151| 반복 10 / 10 | 손실 0.22\n",
            "|에폭 152| 반복 10 / 10 | 손실 0.22\n",
            "|에폭 153| 반복 10 / 10 | 손실 0.22\n",
            "|에폭 154| 반복 10 / 10 | 손실 0.22\n",
            "|에폭 155| 반복 10 / 10 | 손실 0.22\n",
            "|에폭 156| 반복 10 / 10 | 손실 0.21\n",
            "|에폭 157| 반복 10 / 10 | 손실 0.21\n",
            "|에폭 158| 반복 10 / 10 | 손실 0.20\n",
            "|에폭 159| 반복 10 / 10 | 손실 0.21\n",
            "|에폭 160| 반복 10 / 10 | 손실 0.20\n",
            "|에폭 161| 반복 10 / 10 | 손실 0.20\n",
            "|에폭 162| 반복 10 / 10 | 손실 0.20\n",
            "|에폭 163| 반복 10 / 10 | 손실 0.21\n",
            "|에폭 164| 반복 10 / 10 | 손실 0.20\n",
            "|에폭 165| 반복 10 / 10 | 손실 0.20\n",
            "|에폭 166| 반복 10 / 10 | 손실 0.19\n",
            "|에폭 167| 반복 10 / 10 | 손실 0.19\n",
            "|에폭 168| 반복 10 / 10 | 손실 0.19\n",
            "|에폭 169| 반복 10 / 10 | 손실 0.19\n",
            "|에폭 170| 반복 10 / 10 | 손실 0.19\n",
            "|에폭 171| 반복 10 / 10 | 손실 0.19\n",
            "|에폭 172| 반복 10 / 10 | 손실 0.18\n",
            "|에폭 173| 반복 10 / 10 | 손실 0.18\n",
            "|에폭 174| 반복 10 / 10 | 손실 0.18\n",
            "|에폭 175| 반복 10 / 10 | 손실 0.18\n",
            "|에폭 176| 반복 10 / 10 | 손실 0.18\n",
            "|에폭 177| 반복 10 / 10 | 손실 0.18\n",
            "|에폭 178| 반복 10 / 10 | 손실 0.18\n",
            "|에폭 179| 반복 10 / 10 | 손실 0.17\n",
            "|에폭 180| 반복 10 / 10 | 손실 0.17\n",
            "|에폭 181| 반복 10 / 10 | 손실 0.18\n",
            "|에폭 182| 반복 10 / 10 | 손실 0.17\n",
            "|에폭 183| 반복 10 / 10 | 손실 0.18\n",
            "|에폭 184| 반복 10 / 10 | 손실 0.17\n",
            "|에폭 185| 반복 10 / 10 | 손실 0.17\n",
            "|에폭 186| 반복 10 / 10 | 손실 0.18\n",
            "|에폭 187| 반복 10 / 10 | 손실 0.17\n",
            "|에폭 188| 반복 10 / 10 | 손실 0.17\n",
            "|에폭 189| 반복 10 / 10 | 손실 0.17\n",
            "|에폭 190| 반복 10 / 10 | 손실 0.17\n",
            "|에폭 191| 반복 10 / 10 | 손실 0.16\n",
            "|에폭 192| 반복 10 / 10 | 손실 0.17\n",
            "|에폭 193| 반복 10 / 10 | 손실 0.16\n",
            "|에폭 194| 반복 10 / 10 | 손실 0.16\n",
            "|에폭 195| 반복 10 / 10 | 손실 0.16\n",
            "|에폭 196| 반복 10 / 10 | 손실 0.16\n",
            "|에폭 197| 반복 10 / 10 | 손실 0.16\n",
            "|에폭 198| 반복 10 / 10 | 손실 0.15\n",
            "|에폭 199| 반복 10 / 10 | 손실 0.16\n",
            "|에폭 200| 반복 10 / 10 | 손실 0.16\n",
            "|에폭 201| 반복 10 / 10 | 손실 0.15\n",
            "|에폭 202| 반복 10 / 10 | 손실 0.16\n",
            "|에폭 203| 반복 10 / 10 | 손실 0.16\n",
            "|에폭 204| 반복 10 / 10 | 손실 0.15\n",
            "|에폭 205| 반복 10 / 10 | 손실 0.16\n",
            "|에폭 206| 반복 10 / 10 | 손실 0.15\n",
            "|에폭 207| 반복 10 / 10 | 손실 0.15\n",
            "|에폭 208| 반복 10 / 10 | 손실 0.15\n",
            "|에폭 209| 반복 10 / 10 | 손실 0.15\n",
            "|에폭 210| 반복 10 / 10 | 손실 0.15\n",
            "|에폭 211| 반복 10 / 10 | 손실 0.15\n",
            "|에폭 212| 반복 10 / 10 | 손실 0.15\n",
            "|에폭 213| 반복 10 / 10 | 손실 0.15\n",
            "|에폭 214| 반복 10 / 10 | 손실 0.15\n",
            "|에폭 215| 반복 10 / 10 | 손실 0.15\n",
            "|에폭 216| 반복 10 / 10 | 손실 0.14\n",
            "|에폭 217| 반복 10 / 10 | 손실 0.14\n",
            "|에폭 218| 반복 10 / 10 | 손실 0.15\n",
            "|에폭 219| 반복 10 / 10 | 손실 0.14\n",
            "|에폭 220| 반복 10 / 10 | 손실 0.14\n",
            "|에폭 221| 반복 10 / 10 | 손실 0.14\n",
            "|에폭 222| 반복 10 / 10 | 손실 0.14\n",
            "|에폭 223| 반복 10 / 10 | 손실 0.14\n",
            "|에폭 224| 반복 10 / 10 | 손실 0.14\n",
            "|에폭 225| 반복 10 / 10 | 손실 0.14\n",
            "|에폭 226| 반복 10 / 10 | 손실 0.14\n",
            "|에폭 227| 반복 10 / 10 | 손실 0.14\n",
            "|에폭 228| 반복 10 / 10 | 손실 0.14\n",
            "|에폭 229| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 230| 반복 10 / 10 | 손실 0.14\n",
            "|에폭 231| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 232| 반복 10 / 10 | 손실 0.14\n",
            "|에폭 233| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 234| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 235| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 236| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 237| 반복 10 / 10 | 손실 0.14\n",
            "|에폭 238| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 239| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 240| 반복 10 / 10 | 손실 0.14\n",
            "|에폭 241| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 242| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 243| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 244| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 245| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 246| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 247| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 248| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 249| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 250| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 251| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 252| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 253| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 254| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 255| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 256| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 257| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 258| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 259| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 260| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 261| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 262| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 263| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 264| 반복 10 / 10 | 손실 0.13\n",
            "|에폭 265| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 266| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 267| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 268| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 269| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 270| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 271| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 272| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 273| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 274| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 275| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 276| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 277| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 278| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 279| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 280| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 281| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 282| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 283| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 284| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 285| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 286| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 287| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 288| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 289| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 290| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 291| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 292| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 293| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 294| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 295| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 296| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 297| 반복 10 / 10 | 손실 0.12\n",
            "|에폭 298| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 299| 반복 10 / 10 | 손실 0.11\n",
            "|에폭 300| 반복 10 / 10 | 손실 0.11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48152 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48373 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49552 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49892 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48152 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48373 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49552 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49892 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtbT1DzpAUbQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "59218ed4-d775-47da-97b4-427f7a8cafac"
      },
      "source": [
        "# 경계 영역을 보면 나선형 패턴을 올바르게 파악했음을 알 수 있음\n",
        "\n",
        "# 경계 영역 플롯\n",
        "h = 0.001\n",
        "x_min, x_max = x[:, 0].min() - .1, x[:, 0].max() + .1\n",
        "y_min, y_max = x[:, 1].min() - .1, x[:, 1].max() + .1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "X = np.c_[xx.ravel(), yy.ravel()]\n",
        "score = model.predict(X) \n",
        "predict_cls = np.argmax(score, axis=1)\n",
        "Z = predict_cls.reshape(xx.shape)\n",
        "plt.contourf(xx, yy, Z)\n",
        "plt.axis('off')\n",
        "\n",
        "# 데이터점 플롯\n",
        "x, t = spiral.load_data()\n",
        "N = 100\n",
        "CLS_NUM = 3\n",
        "markers = ['o', 'x', '^']\n",
        "for i in range(CLS_NUM):\n",
        "    plt.scatter(x[i*N:(i+1)*N, 0], x[i*N:(i+1)*N, 1], s=40, marker=markers[i])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhT5gUxDIzM0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e27dfeb6-1737-4aae-f949-a15b8e0fb1e3"
      },
      "source": [
        "import sys, os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/deep-learning-from-scratch-2-master\")\n",
        "from common.optimizer import SGD\n",
        "from common.trainer import Trainer\n",
        "from dataset import spiral\n",
        "from two_layer_net import TwoLayerNet\n",
        "\n",
        "max_epoch = 300\n",
        "batch_size = 30\n",
        "hidden_size = 10\n",
        "learning_rate = 1.0\n",
        "x, t = spiral.load_data()\n",
        "model = TwoLayerNet(input_size = 2, hidden_size = hidden_size, output_size = 3)\n",
        "optimizer = SGD(lr=learning_rate)\n",
        "\n",
        "# 앞에 했던 내용을 간단하게 Trainer 라는 클래스로 묶었을 뿐임.\n",
        "trainer = Trainer(model, optimizer)\n",
        "trainer.fit(x, t, max_epoch, batch_size, eval_interval = 10)\n",
        "trainer.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| 에폭 1 |  반복 1 / 10 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 2 |  반복 1 / 10 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 3 |  반복 1 / 10 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 4 |  반복 1 / 10 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 5 |  반복 1 / 10 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 6 |  반복 1 / 10 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 7 |  반복 1 / 10 | 시간 0[s] | 손실 1.14\n",
            "| 에폭 8 |  반복 1 / 10 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 9 |  반복 1 / 10 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 10 |  반복 1 / 10 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 11 |  반복 1 / 10 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 12 |  반복 1 / 10 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 13 |  반복 1 / 10 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 14 |  반복 1 / 10 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 15 |  반복 1 / 10 | 시간 0[s] | 손실 1.08\n",
            "| 에폭 16 |  반복 1 / 10 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 17 |  반복 1 / 10 | 시간 0[s] | 손실 1.03\n",
            "| 에폭 18 |  반복 1 / 10 | 시간 0[s] | 손실 0.94\n",
            "| 에폭 19 |  반복 1 / 10 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 20 |  반복 1 / 10 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 21 |  반복 1 / 10 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 22 |  반복 1 / 10 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 23 |  반복 1 / 10 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 24 |  반복 1 / 10 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 25 |  반복 1 / 10 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 26 |  반복 1 / 10 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 27 |  반복 1 / 10 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 28 |  반복 1 / 10 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 29 |  반복 1 / 10 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 30 |  반복 1 / 10 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 31 |  반복 1 / 10 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 32 |  반복 1 / 10 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 33 |  반복 1 / 10 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 34 |  반복 1 / 10 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 35 |  반복 1 / 10 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 36 |  반복 1 / 10 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 37 |  반복 1 / 10 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 38 |  반복 1 / 10 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 39 |  반복 1 / 10 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 40 |  반복 1 / 10 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 41 |  반복 1 / 10 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 42 |  반복 1 / 10 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 43 |  반복 1 / 10 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 44 |  반복 1 / 10 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 45 |  반복 1 / 10 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 46 |  반복 1 / 10 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 47 |  반복 1 / 10 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 48 |  반복 1 / 10 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 49 |  반복 1 / 10 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 50 |  반복 1 / 10 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 51 |  반복 1 / 10 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 52 |  반복 1 / 10 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 53 |  반복 1 / 10 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 54 |  반복 1 / 10 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 55 |  반복 1 / 10 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 56 |  반복 1 / 10 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 57 |  반복 1 / 10 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 58 |  반복 1 / 10 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 59 |  반복 1 / 10 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 60 |  반복 1 / 10 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 61 |  반복 1 / 10 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 62 |  반복 1 / 10 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 63 |  반복 1 / 10 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 64 |  반복 1 / 10 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 65 |  반복 1 / 10 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 66 |  반복 1 / 10 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 67 |  반복 1 / 10 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 68 |  반복 1 / 10 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 69 |  반복 1 / 10 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 70 |  반복 1 / 10 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 71 |  반복 1 / 10 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 72 |  반복 1 / 10 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 73 |  반복 1 / 10 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 74 |  반복 1 / 10 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 75 |  반복 1 / 10 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 76 |  반복 1 / 10 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 77 |  반복 1 / 10 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 78 |  반복 1 / 10 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 79 |  반복 1 / 10 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 80 |  반복 1 / 10 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 81 |  반복 1 / 10 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 82 |  반복 1 / 10 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 83 |  반복 1 / 10 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 84 |  반복 1 / 10 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 85 |  반복 1 / 10 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 86 |  반복 1 / 10 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 87 |  반복 1 / 10 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 88 |  반복 1 / 10 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 89 |  반복 1 / 10 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 90 |  반복 1 / 10 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 91 |  반복 1 / 10 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 92 |  반복 1 / 10 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 93 |  반복 1 / 10 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 94 |  반복 1 / 10 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 95 |  반복 1 / 10 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 96 |  반복 1 / 10 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 97 |  반복 1 / 10 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 98 |  반복 1 / 10 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 99 |  반복 1 / 10 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 100 |  반복 1 / 10 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 101 |  반복 1 / 10 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 102 |  반복 1 / 10 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 103 |  반복 1 / 10 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 104 |  반복 1 / 10 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 105 |  반복 1 / 10 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 106 |  반복 1 / 10 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 107 |  반복 1 / 10 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 108 |  반복 1 / 10 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 109 |  반복 1 / 10 | 시간 0[s] | 손실 0.40\n",
            "| 에폭 110 |  반복 1 / 10 | 시간 0[s] | 손실 0.41\n",
            "| 에폭 111 |  반복 1 / 10 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 112 |  반복 1 / 10 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 113 |  반복 1 / 10 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 114 |  반복 1 / 10 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 115 |  반복 1 / 10 | 시간 0[s] | 손실 0.36\n",
            "| 에폭 116 |  반복 1 / 10 | 시간 0[s] | 손실 0.34\n",
            "| 에폭 117 |  반복 1 / 10 | 시간 0[s] | 손실 0.35\n",
            "| 에폭 118 |  반복 1 / 10 | 시간 0[s] | 손실 0.33\n",
            "| 에폭 119 |  반복 1 / 10 | 시간 0[s] | 손실 0.35\n",
            "| 에폭 120 |  반복 1 / 10 | 시간 0[s] | 손실 0.33\n",
            "| 에폭 121 |  반복 1 / 10 | 시간 0[s] | 손실 0.33\n",
            "| 에폭 122 |  반복 1 / 10 | 시간 0[s] | 손실 0.32\n",
            "| 에폭 123 |  반복 1 / 10 | 시간 0[s] | 손실 0.31\n",
            "| 에폭 124 |  반복 1 / 10 | 시간 0[s] | 손실 0.31\n",
            "| 에폭 125 |  반복 1 / 10 | 시간 0[s] | 손실 0.31\n",
            "| 에폭 126 |  반복 1 / 10 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 127 |  반복 1 / 10 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 128 |  반복 1 / 10 | 시간 0[s] | 손실 0.27\n",
            "| 에폭 129 |  반복 1 / 10 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 130 |  반복 1 / 10 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 131 |  반복 1 / 10 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 132 |  반복 1 / 10 | 시간 0[s] | 손실 0.27\n",
            "| 에폭 133 |  반복 1 / 10 | 시간 0[s] | 손실 0.27\n",
            "| 에폭 134 |  반복 1 / 10 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 135 |  반복 1 / 10 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 136 |  반복 1 / 10 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 137 |  반복 1 / 10 | 시간 0[s] | 손실 0.25\n",
            "| 에폭 138 |  반복 1 / 10 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 139 |  반복 1 / 10 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 140 |  반복 1 / 10 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 141 |  반복 1 / 10 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 142 |  반복 1 / 10 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 143 |  반복 1 / 10 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 144 |  반복 1 / 10 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 145 |  반복 1 / 10 | 시간 0[s] | 손실 0.24\n",
            "| 에폭 146 |  반복 1 / 10 | 시간 0[s] | 손실 0.24\n",
            "| 에폭 147 |  반복 1 / 10 | 시간 0[s] | 손실 0.25\n",
            "| 에폭 148 |  반복 1 / 10 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 149 |  반복 1 / 10 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 150 |  반복 1 / 10 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 151 |  반복 1 / 10 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 152 |  반복 1 / 10 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 153 |  반복 1 / 10 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 154 |  반복 1 / 10 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 155 |  반복 1 / 10 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 156 |  반복 1 / 10 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 157 |  반복 1 / 10 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 158 |  반복 1 / 10 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 159 |  반복 1 / 10 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 160 |  반복 1 / 10 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 161 |  반복 1 / 10 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 162 |  반복 1 / 10 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 163 |  반복 1 / 10 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 164 |  반복 1 / 10 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 165 |  반복 1 / 10 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 166 |  반복 1 / 10 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 167 |  반복 1 / 10 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 168 |  반복 1 / 10 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 169 |  반복 1 / 10 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 170 |  반복 1 / 10 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 171 |  반복 1 / 10 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 172 |  반복 1 / 10 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 173 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 174 |  반복 1 / 10 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 175 |  반복 1 / 10 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 176 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 177 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 178 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 179 |  반복 1 / 10 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 180 |  반복 1 / 10 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 181 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 182 |  반복 1 / 10 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 183 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 184 |  반복 1 / 10 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 185 |  반복 1 / 10 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 186 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 187 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 188 |  반복 1 / 10 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 189 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 190 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 191 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 192 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 193 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 194 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 195 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 196 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 197 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 198 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 199 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 200 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 201 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 202 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 203 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 204 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 205 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 206 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 207 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 208 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 209 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 210 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 211 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 212 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 213 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 214 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 215 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 216 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 217 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 218 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 219 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 220 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 221 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 222 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 223 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 224 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 225 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 226 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 227 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 228 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 229 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 230 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 231 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 232 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 233 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 234 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 235 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 236 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 237 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 238 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 239 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 240 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 241 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 242 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 243 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 244 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 245 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 246 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 247 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 248 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 249 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 250 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 251 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 252 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 253 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 254 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 255 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 256 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 257 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 258 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 259 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 260 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 261 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 262 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 263 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 264 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 265 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 266 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 267 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 268 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 269 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 270 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 271 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 272 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 273 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 274 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 275 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 276 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 277 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 278 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 279 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 280 |  반복 1 / 10 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 281 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 282 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 283 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 284 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 285 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 286 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 287 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 288 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 289 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 290 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 291 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 292 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 293 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 294 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 295 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 296 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 297 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 298 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 299 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 300 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48152 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48373 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49552 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49892 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48152 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48373 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49552 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49892 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rILak7IH9vv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "775e0bd1-e5e2-4201-a47c-faecccbc9aa2"
      },
      "source": [
        "import numpy as np\n",
        "a = np.random.randn(3)\n",
        "print(a.dtype)\n",
        "# 넘파이의 부동소수점 수는 기본적으로 64비트 데이터 타입을 사용함\n",
        "# 그러나 신경망의 추론과 학습은 32비트에서도 문제없이 잘 작동하기 때문에\n",
        "# 32비트로 떨어뜨려주는게 계산속도를 증가시키는데에 용이함.\n",
        "b = np.random.randn(3).astype(np.float32)\n",
        "print(b.dtype)\n",
        "c = np.random.randn(3).astype('f')\n",
        "print(c.dtype)\n",
        "# np.float32 나 f로 지정하면 32비트로 변경\n",
        "# 신경망 추론으로 한정하면 16비트를 사용해도 인식률이 거의 떨어지지 않음.\n",
        "# 다만 일반적으로 CPU와 GPU는 연산자체를 32비트로 수행하기 때문에 \n",
        "# 처리 속도 측면에서는 혜택이 없을 수도 있음.\n",
        "# 그러나 학습된 가중치를 저장할 때는 16비트 부동소수점 수가 여전히 유효함. (데이터가 절반이므로)\n",
        "# 그래서 이 책에서는 학습된 가중치를 저장하는 경우에 한해 16비트 부동소수점 수로 변환함.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "float64\n",
            "float32\n",
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrJx3pqNLqSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a8e993a1-4d00-44d7-dc3b-9cc7f6a2e130"
      },
      "source": [
        "'''\n",
        "import cupy as cp\n",
        "x = cp.arange(6).reshape(2, 3).astype('f')\n",
        "print(x)\n",
        "'''\n",
        "# 대량의 곱하기 연산은 병렬로 계산되는데 이 점에서는\n",
        "# CPU 보다 GPU가 훨씬 유리함. 그래서 GPU 사용에 대해 설명\n",
        "# 쿠파이는 GPU를 이용해 병렬 계산을 수행해 주는 라이브러리임.\n",
        "# 쿠파이의 사용방법은 기본적으로 넘파이와 같음.\n",
        "# 사용법은 같지만 뒤에서 열심히 GPU를 사용해 계산하는 것.\n",
        "# 보통은 numpy를 cupy로 대체해주기만 하면 끝"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nimport cupy as cp\\nx = cp.arange(6).reshape(2, 3).astype('f')\\nprint(x)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goYE__qvQVft",
        "colab_type": "text"
      },
      "source": [
        "### 2장 - 자연어와 단어의 분산 표현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF_qxoMYOey3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "96194c46-485f-4ec9-ab7f-9fd500a78399"
      },
      "source": [
        "text = 'You say goodbye and I say hello.'\n",
        "text = text.lower() # 모든 문자를 소문자로 변환\n",
        "text = text.replace('.', ' .')  # (.) 을  ( .) 로 변환\n",
        "text\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'you say goodbye and i say hello .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9KrxrCBxYD8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83d5da2c-4f76-4b85-817f-110393c56971"
      },
      "source": [
        "words = text.split(' ') # 공백을 기준으로 분할\n",
        "words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwoY9gXHxcmQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "02ff8c33-5d48-4cf0-e369-4acb10acee4c"
      },
      "source": [
        "word_to_id = {}\n",
        "id_to_word = {}\n",
        "\n",
        "for word in words:\n",
        "  if word not in word_to_id:\n",
        "    new_id = len(word_to_id)\n",
        "    word_to_id[word] = new_id\n",
        "    id_to_word[new_id] = word\n",
        "\n",
        "print(id_to_word)\n",
        "print(word_to_id)\n",
        "\n",
        "print(id_to_word[1])\n",
        "print(word_to_id['hello'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
            "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
            "say\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lopjwd4NyRJy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33188fcb-fb0b-4a53-e0b0-4386a7342e56"
      },
      "source": [
        "import numpy as np\n",
        "corpus = [word_to_id[w] for w in words]\n",
        "corpus = np.array(corpus)\n",
        "corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 1, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zan1UjN7zzf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def preprocess(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace('.', ' .')\n",
        "  words = text.split(' ')\n",
        "  word_to_id = {}\n",
        "  id_to_word = {}\n",
        "  for word in words:\n",
        "    if word not in word_to_id:\n",
        "      new_id = len(word_to_id)\n",
        "      word_to_id[word] = new_id\n",
        "      id_to_word[new_id] = word\n",
        "\n",
        "  corpus = np.array([word_to_id[w] for w in words])\n",
        "\n",
        "\n",
        "  return corpus, word_to_id, id_to_word "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf_k9ANU0QLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65qXnN2Q02pg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2e4f27bc-68d3-4c6b-8efd-d4345e6e68e2"
      },
      "source": [
        "import sys, os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append(os.pardir)\n",
        "import numpy as np\n",
        "from common.util import preprocess\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "\n",
        "print(corpus)\n",
        "\n",
        "print(id_to_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 1 5 6]\n",
            "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDEF2xno1V1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_co_matrix(corpus, vocab_size, window_size = 1):\n",
        "  corpus_size = len(corpus)\n",
        "  co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
        "\n",
        "  for idx, word_id in enumerate(corpus): # 순서가 있는 자료형에서 index 번호와 index 값을 반환함.    \n",
        "  # 이 경우에서 corpus는 [0 1 2 3 4 1 5 6] 이므로 idx는 [0 1 2 3 4 5 6 7] word_id는 [0 1 2 3 4 1 5 6] 임.\n",
        "    for i in range(1, window_size + 1):\n",
        "      left_idx = idx - i\n",
        "      right_idx = idx + i\n",
        "      # 제일 왼쪽 인덱스랑 오른쪽 인덱스의 왼쪽/ 오른쪽은 word의 len를 벗어나니까 그걸 방지하기 위해서 밑에 코드가 있음.\n",
        "\n",
        "      if left_idx >= 0 :  \n",
        "        left_word_id = corpus[left_idx]\n",
        "        co_matrix[word_id, left_word_id] += 1\n",
        "\n",
        "      if right_idx < corpus_size:\n",
        "        right_word_id = corpus[right_idx] # 여기서 corpus[] 는 value 값임.\n",
        "        co_matrix[word_id, right_word_id] += 1\n",
        "  return co_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-psULK73AI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "def cos_similarity(x, y):\n",
        "  nx = x / np.sqrt(np.sum(x**2)) # x의 정규화\n",
        "  ny = y / np.sqrt(np.sum(y**2)) # y의 정규화\n",
        "  return np.dot(nx, ny)\n",
        "'''\n",
        " # 위에서는 x나 y가 0일 때 분모에 문제가 생기므로 분모에 아주 작은 값을 더해주면 효율적인 계산이 가능함\n",
        "def cos_similarity(x, y, eps=1e-8):\n",
        "  nx = x / np.sqrt(np.sum(x**2) + eps) \n",
        "  ny = y / np.sqrt(np.sum(y**2) + eps) \n",
        "  return np.dot(nx, ny)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0nB9UuX7-4P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51a292f7-4ca2-4a22-d9fd-76ad6c8e18b5"
      },
      "source": [
        "import sys, os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append(os.pardir)\n",
        "from common.util import preprocess, create_co_matrix, cos_similarity\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(word_to_id)\n",
        "C = create_co_matrix(corpus, vocab_size)\n",
        "\n",
        "c0 = C[word_to_id['you']] # \"you\" 의 단어 벡터\n",
        "c1 = C[word_to_id['i']] # \"i\" 의  단어 벡터\n",
        "print(cos_similarity(c0, c1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7071067691154799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FImnDivB-qyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def most_similar(query, word_to_id, id_to_word, word_matrix, top = 5):\n",
        "  # 검색어를 꺼낸다.\n",
        "  if query not in word_to_id:\n",
        "    print('%s(을)를 찾을 수 없습니다.' %query)\n",
        "    return\n",
        "  \n",
        "  print('\\n[query]' + query)\n",
        "  query_id = word_to_id[query]\n",
        "  query_vec = word_matrix[query_id]\n",
        "\n",
        "  # 코사인 유사도 계산\n",
        "  vocab_size = len(id_to_word)\n",
        "  similarity = np.zeros(vocab_size)\n",
        "  \n",
        "  for i in range(vocab_size):\n",
        "    similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
        "\n",
        "  # 코사인 유사도를 기준으로 내림차순으로 출력\n",
        "  count = 0\n",
        "  for i in ( -1 * similarity).argsort(): # argsort의 의미는 배열의 원소를 오름차순으로 정렬하는 것. 그런데 여기서는 similarity 에 -1을 곱했으니 내림차순으로 바뀜.\n",
        "    if id_to_word[i] == query:\n",
        "      continue\n",
        "    print(' %s: %s' %(id_to_word[i], similarity[i]))\n",
        "\n",
        "    count += 1\n",
        "    if count >= top:\n",
        "      return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0FkvwszGruk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "b35a8bab-cb1c-4742-9623-a2cf3f1d43d9"
      },
      "source": [
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "C = create_co_matrix(corpus, vocab_size)\n",
        "most_similar('you', word_to_id, id_to_word, C)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[query]you\n",
            " goodbye: 0.7071067691154799\n",
            " i: 0.7071067691154799\n",
            " hello: 0.7071067691154799\n",
            " say: 0.0\n",
            " and: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDD55JTMKSL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c2a66641-144a-4b40-ecc1-a702ec0237ab"
      },
      "source": [
        "# argsort()의 의미를 잘 생각해 볼 것.\n",
        "x = np.array([100, -20, 2]) \n",
        "print(x.argsort()) # 오름차순 정렬\n",
        "print((-x).argsort()) # 각 원소에 -1을 곱했으니 내림차순 정렬이 됨."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2 0]\n",
            "[0 2 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIAI03HtKvnE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "16606b27-90de-4704-f27d-d43a528191a3"
      },
      "source": [
        "import sys, os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append(os.pardir)\n",
        "\n",
        "from common.util import preprocess, create_co_matrix, most_similar\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(word_to_id) \n",
        "# word to id {'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6} \n",
        "# 단어들을 어떤 value로 표현해준다고 생각하면 쉬움.\n",
        "C = create_co_matrix(corpus, vocab_size)\n",
        "\n",
        "most_similar('you', word_to_id, id_to_word, C, top=5)\n",
        "\n",
        "# 위의 코드는 기존 적어놨던 코드를 이용해서 구현했음."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[query] you\n",
            " goodbye: 0.7071067691154799\n",
            " i: 0.7071067691154799\n",
            " hello: 0.7071067691154799\n",
            " say: 0.0\n",
            " and: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kn6gEfcLqK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 상호정보량\n",
        "# x,y의 관련성에 대해 설명하는 내용인데 얼마나 많이 등장하느냐에 대한 확률로 표현함.\n",
        "# 이것이 왜 중요하냐면, 예컨대 the, car, drive 사이의 양의 상호정보량에 대해 생각을 해보자.\n",
        "# 분명히 car 앞에는 the가 많이 붙어있을 것임. 그러나 car는 the와 별로 관련이 없는 단어이고 오히려 drive와 관련이 큼.\n",
        "# 예로, the가 1000번, car가 20번, drive가 10번 등장하는 말뭉치가 있다고 가정해봄.\n",
        "# 이 때, the와 car가 동시에 등장하는 횟수는 10 , car와 drive가 동시에 등장하는 횟수는 5라고 생각해보자.\n",
        "# 이러면 상호정보량은 당연히 car와 drive 사이에서의 값이 더 높음. \n",
        "# 왜냐면 the는 car가 아니어도 많이 나오기 때문. 즉 독립적으로 나오는 횟수를 고려하기 때문임.\n",
        "# 근데 여기서, log 함수를 사용하기 때문에 log가 0에 가까워지면, 즉 x,y가 출현을 거의 안한다면 문제가 됨.\n",
        "# 따라서 PPMI = max(0,PMI(x,y)) 로 양의 값으로 바꿔주면 계산에 아주 유용할 듯."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ziQpdRVNTKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 단어 사이의 관련성을 0 이상의 실수로 나타내는 함수\n",
        "# verbose는 진행상황 출력 여부를 결정하는 플래그\n",
        "# 큰 말뭉치를 다룰 때 verbose= True 로 설정하면 중간중간 진행 상황을 알려줌.\n",
        "def ppmi(C, verbose=False, eps = 1e-8):   \n",
        "  M = np.zeros_like(C, dtype=np.float32)\n",
        "  N = np.sum(C)\n",
        "  S = np.sum(C, axis=0)\n",
        "  total = C.shpae[0] * C.shape[1]\n",
        "  cnt = 0\n",
        "\n",
        "  for i in range(C.shape[0]):\n",
        "    for j in range(C.shape[1]):\n",
        "      pmi = np.log2(C[i, j] * N / (S[j]*S[i] + eps)) # log2는 밑이 2인 로그\n",
        "      M[i, j] = max(0, pmi)\n",
        "\n",
        "      if verbose:\n",
        "        cnt += 1\n",
        "        if cnt % (total // 100) == 0:\n",
        "          print('%.1f%% 완료' %(100*cnt/total))\n",
        "  return M\n",
        "\n",
        "# 이 코드는 동시발생 행렬에 대해서만 PPMI 행렬을 구할 수 있도록 하고자 단순화 해서 구현했음.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSA7X3B8OR39",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "669f50cf-2c50-45fc-ddcd-b3fe4a7d7594"
      },
      "source": [
        "# 동시발생 행렬을 PPMI 행렬로 변환해보자.\n",
        "import sys, os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append(os.pardir)\n",
        "import numpy as np\n",
        "from common.util import preprocess, create_co_matrix, cos_similarity, ppmi\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(word_to_id)\n",
        "C = create_co_matrix(corpus, vocab_size)\n",
        "W = ppmi(C)\n",
        "\n",
        "np.set_printoptions(precision=3) # 유효 자릿수를 세 자리로 표시\n",
        "print('동시발생 행렬')\n",
        "print(C)\n",
        "print('-'* 50)\n",
        "print('PPMI')\n",
        "print(W)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "동시발생 행렬\n",
            "[[0 1 0 0 0 0 0]\n",
            " [1 0 1 0 1 1 0]\n",
            " [0 1 0 1 0 0 0]\n",
            " [0 0 1 0 1 0 0]\n",
            " [0 1 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 0]]\n",
            "--------------------------------------------------\n",
            "PPMI\n",
            "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
            " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
            " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
            " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
            " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
            " [0.    0.807 0.    0.    0.    0.    2.807]\n",
            " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLdfTJEyQDoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 차원감소\n",
        "# PPMI 행렬에도 큰 문제가 있음. 말뭉치의 어휘 수가 10만 개라면 그 벡터의 차원 수도 똑같이 10만이 됨.\n",
        "# 10만 차원의 벡터를 다룬다는 것은 그다지 현실적이지 않음.\n",
        "# 행렬의 내용을 들여다보면 원소 대부분이 0인 것을 알 수 있음. \n",
        "# 벡터의 원소 대부분이 중요하지 않다는 뜻인데 그렇다면 '중요한 정보'는 최대한 유지하면서 차원을 줄이는게 핵심이 됨.\n",
        "# 새로운 축을 도입하여 똑같은 데이터를 좌표축 하나만으로 표시한 그림 확인.\n",
        "# 여기서 중요한 것은 가장 적합한 축을 찾아내는 일로, 1차원 값만으로도 데이터의 본질적인 차이를 구별할 수 있어야 함.\n",
        "# 그 방법으로 SVD 방법을 사용함. 책을 확인하면 더 자세하게 나와있음."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6n6ztCyRb_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVD를 파이썬 코드로 살펴보자. \n",
        "# linalg 모듈이 제공하는 svd 메서드로 실행할 수 있음. linalg는 선형대수의 약어임.\n",
        "import os, sys\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append(os.pardir)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from common.util import preprocess, create_co_matrix, ppmi\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(id_to_word)\n",
        "C = create_co_matrix(corpus, vocab_size, window_size = 1)\n",
        "W = ppmi(C)\n",
        "\n",
        "# SVD\n",
        "U, S, V = np.linalg.svd(W)\n",
        "\n",
        "# 동시 발생 행렬을 만들어 PPMI 행렬로 변환한 다음 SVD를 적용시킴."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnJc6l_dR9sO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "3ecd66f4-38f2-4cf6-9a46-94c55ae9dbf5"
      },
      "source": [
        "print(C[0]) # 동시발생 행렬\n",
        "print(W[0]) # PPMI 행렬\n",
        "print(U[0]) # SVD\n",
        "print(U[0, :2]) # 2차원 벡터로 줄이려면 단순히 처음의 두 원소를 꺼내면 됨."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 0 0 0]\n",
            "[0.    1.807 0.    0.    0.    0.    0.   ]\n",
            "[ 3.409e-01  0.000e+00 -1.205e-01 -3.886e-16 -9.323e-01 -1.110e-16\n",
            " -2.426e-17]\n",
            "[0.341 0.   ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVvm1l-3SLLj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a52d1d8e-e312-4655-e05b-a7dd23f82150"
      },
      "source": [
        "for word, word_id in word_to_id.items():\n",
        "  plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
        "\n",
        "plt.scatter(U[:,0], U[:,1], alpha=0.5)\n",
        "plt.show()\n",
        "\n",
        "# plt.annotate(word,x,y) 메서드는 2차원 그래프상에서 좌표(x,y) 지점에 word에 담긴 텍스트를 그림.\n",
        "# 그림을 보면 goodbye 와 hello, you, i 가 제법 가까이 있음을 알 수 있음."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxTXyAlZSjCr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "b1bacf4b-19bc-44e7-c9c9-487d043c8364"
      },
      "source": [
        "import sys, os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append(os.chdir)\n",
        "\n",
        "from dataset import ptb\n",
        "\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "\n",
        "print('말뭉치 크기:' , len(corpus))\n",
        "print('corpus[:30]', corpus[:30])\n",
        "print()\n",
        "print('id_to_word[0]:', id_to_word[0])\n",
        "print('id_to_word[1]:', id_to_word[1])\n",
        "print('id_to_word[2]:', id_to_word[2])\n",
        "print()\n",
        "print(\"word_to_id['car']:\", word_to_id['car'])\n",
        "print(\"word_to_id['happy']:\", word_to_id['happy'])\n",
        "print(\"word_to_id['lexus']:\", word_to_id['lexus'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "말뭉치 크기: 929589\n",
            "corpus[:30] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "\n",
            "id_to_word[0]: aer\n",
            "id_to_word[1]: banknote\n",
            "id_to_word[2]: berlitz\n",
            "\n",
            "word_to_id['car']: 3856\n",
            "word_to_id['happy']: 4428\n",
            "word_to_id['lexus']: 7426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6TlThHF4lnm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eba00f94-3d72-4695-dd75-c4a3e6079cc0"
      },
      "source": [
        "import sys\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append(os.pardir)\n",
        "import numpy as np\n",
        "from common.util import most_similar, create_co_matrix, ppmi\n",
        "from dataset import ptb\n",
        "\n",
        "window_size = 2\n",
        "wordvec_size = 100\n",
        "\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "vocab_size = len(word_to_id)\n",
        "print('동시발생 수 계산 ...')\n",
        "C = create_co_matrix(corpus, vocab_size, window_size) \n",
        "# 윈도우 크기가 2면 타깃 단어 좌우 2단어씩을 맥락에 포함\n",
        "print('PPMI 계산 ...')\n",
        "W = ppmi(C, verbose=True)\n",
        "\n",
        "print('SVD 계산 ...')\n",
        "try:\n",
        "  # truncated SVD( 빠르다! )\n",
        "  from sklearn.utils.extmath import randomized_svd\n",
        "  U, S, V = randomized_svd(W, n_components = wordvec_size, n_iter=5, random_state=None)\n",
        "\n",
        "except ImportError:\n",
        "  # SVD (느리다)\n",
        "  U, S, V = np.linalg.svd(W)\n",
        "\n",
        "word_vecs = U[:, :wordvec_size] # U의 행전체, 열은 100까지만. (차원축소 인듯.)\n",
        " \n",
        "querys = ['you', 'year', 'car', 'toyota']\n",
        "for query in querys:\n",
        "  most_similar(query, word_to_id, id_to_word, word_vecs, top = 5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "동시발생 수 계산 ...\n",
            "PPMI 계산 ...\n",
            "1.0% 완료\n",
            "2.0% 완료\n",
            "3.0% 완료\n",
            "4.0% 완료\n",
            "5.0% 완료\n",
            "6.0% 완료\n",
            "7.0% 완료\n",
            "8.0% 완료\n",
            "9.0% 완료\n",
            "10.0% 완료\n",
            "11.0% 완료\n",
            "12.0% 완료\n",
            "13.0% 완료\n",
            "14.0% 완료\n",
            "15.0% 완료\n",
            "16.0% 완료\n",
            "17.0% 완료\n",
            "18.0% 완료\n",
            "19.0% 완료\n",
            "20.0% 완료\n",
            "21.0% 완료\n",
            "22.0% 완료\n",
            "23.0% 완료\n",
            "24.0% 완료\n",
            "25.0% 완료\n",
            "26.0% 완료\n",
            "27.0% 완료\n",
            "28.0% 완료\n",
            "29.0% 완료\n",
            "30.0% 완료\n",
            "31.0% 완료\n",
            "32.0% 완료\n",
            "33.0% 완료\n",
            "34.0% 완료\n",
            "35.0% 완료\n",
            "36.0% 완료\n",
            "37.0% 완료\n",
            "38.0% 완료\n",
            "39.0% 완료\n",
            "40.0% 완료\n",
            "41.0% 완료\n",
            "42.0% 완료\n",
            "43.0% 완료\n",
            "44.0% 완료\n",
            "45.0% 완료\n",
            "46.0% 완료\n",
            "47.0% 완료\n",
            "48.0% 완료\n",
            "49.0% 완료\n",
            "50.0% 완료\n",
            "51.0% 완료\n",
            "52.0% 완료\n",
            "53.0% 완료\n",
            "54.0% 완료\n",
            "55.0% 완료\n",
            "56.0% 완료\n",
            "57.0% 완료\n",
            "58.0% 완료\n",
            "59.0% 완료\n",
            "60.0% 완료\n",
            "61.0% 완료\n",
            "62.0% 완료\n",
            "63.0% 완료\n",
            "64.0% 완료\n",
            "65.0% 완료\n",
            "66.0% 완료\n",
            "67.0% 완료\n",
            "68.0% 완료\n",
            "69.0% 완료\n",
            "70.0% 완료\n",
            "71.0% 완료\n",
            "72.0% 완료\n",
            "73.0% 완료\n",
            "74.0% 완료\n",
            "75.0% 완료\n",
            "76.0% 완료\n",
            "77.0% 완료\n",
            "78.0% 완료\n",
            "79.0% 완료\n",
            "80.0% 완료\n",
            "81.0% 완료\n",
            "82.0% 완료\n",
            "83.0% 완료\n",
            "84.0% 완료\n",
            "85.0% 완료\n",
            "86.0% 완료\n",
            "87.0% 완료\n",
            "88.0% 완료\n",
            "89.0% 완료\n",
            "90.0% 완료\n",
            "91.0% 완료\n",
            "92.0% 완료\n",
            "93.0% 완료\n",
            "94.0% 완료\n",
            "95.0% 완료\n",
            "96.0% 완료\n",
            "97.0% 완료\n",
            "98.0% 완료\n",
            "99.0% 완료\n",
            "100.0% 완료\n",
            "SVD 계산 ...\n",
            "\n",
            "[query] you\n",
            " i: 0.6468660831451416\n",
            " we: 0.6108704805374146\n",
            " anybody: 0.6040822863578796\n",
            " do: 0.5814424157142639\n",
            " always: 0.5622100234031677\n",
            "\n",
            "[query] year\n",
            " month: 0.729286253452301\n",
            " quarter: 0.6694890260696411\n",
            " earlier: 0.6335133910179138\n",
            " february: 0.6110854744911194\n",
            " last: 0.5926453471183777\n",
            "\n",
            "[query] car\n",
            " auto: 0.6244403719902039\n",
            " luxury: 0.6134950518608093\n",
            " truck: 0.5803208351135254\n",
            " vehicle: 0.5529912114143372\n",
            " cars: 0.5499685406684875\n",
            "\n",
            "[query] toyota\n",
            " motor: 0.7061044573783875\n",
            " nissan: 0.6875864863395691\n",
            " motors: 0.6356449723243713\n",
            " honda: 0.6053351759910583\n",
            " lexus: 0.5914918780326843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jJfSu7MfnTe",
        "colab_type": "text"
      },
      "source": [
        "## 3장 - word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-QnQkiofF6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}